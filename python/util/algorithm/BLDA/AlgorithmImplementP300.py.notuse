# from paradigm.P300Face import P300Face
# from Algorithm.Interface.Model.ReportModel import ReportModel
# from Algorithm.CCA import CCA
from scipy import signal
import numpy as np
import os
from sklearn.model_selection import KFold
# import math
from paradigm.config.stimulation_config import StimulationConfig
from Algorithm.Supplementary_function import find_element
from Algorithm.algorithm_config import AlgorithmConfig
import time
from Algorithm.Supplementary_function import channel_name_to_index, cal_acc, round_average, cal_char_acc
from Algorithm.BLDA import BLDA, post_process_y_prob


class AlgorithmImplementP300():
    # 类属性：范式名称
    PARADIGMNAME = 'P300'

    def __init__(self, path):

        # 如果外部没有传入被试名称，这边传入一个基础名称，命名为日期
        self.sub_name = time.strftime(
            '%Y_%m_%d_%H_%M', time.localtime(time.time()))
        # 定义采样率，原始采样频率为1000，下采样至250 Hz 频率设置的时候请注意整除问题250/X & cal_time*X
        self.sample_rate = AlgorithmConfig.SAMPLE_RATE
        # 选择导联名称，考虑采用长度固定的布尔向量存储通道选择的索引
        self.select_channel_name = AlgorithmConfig.SELECT_CHANNEL_NAME
        # 计算长度
        self.cal_len: int = AlgorithmConfig.CAL_LEN
        # 下采样程度
        self.down_sample_rate = AlgorithmConfig.DOWN_SAMPLE_RATE
        # 滤波器参数
        self.filter_param = AlgorithmConfig.FILTER_PARAM
        # 交叉验证次数
        self.cv_num = AlgorithmConfig.CV_NUM

        # 初始化算法
        self.method = BLDA(name=AlgorithmConfig.METHOD_NAME)

        # 是否需要做重参考
        self.re_samp = AlgorithmConfig.RE_SAMP
        # self.re_samp = []

        # 第一个刺激的标签
        self.smallest_tar_evt = min(StimulationConfig.TRIAL_START_TRIGGER)
        # trial开始trigger
        self.trial_start_trig: list = StimulationConfig.TRIAL_START_TRIGGER
        # round结束输出trigger
        self.round_end_trig: int = StimulationConfig.ROUND_END_TRIGGER
        # trial结束输出trigger,这里面trial的定义是可以输出一个目标
        self.trial_end_trig: int = StimulationConfig.TRIAL_END_TRIGGER
        # block启动输出trigger
        self.block_start_trig: int = StimulationConfig.BLOCK_START_TRIGGER
        # block结束输出trigger
        self.block_end_trig: int = StimulationConfig.BLOCK_END_TRIGGER
        # 数据开始记录trigger
        self.record_start_trig: int = StimulationConfig.RECORD_START_TRIGGER
        # 数据停止记录trigger
        self.record_end_trig: int = StimulationConfig.RECORD_END_TRIGGER
        # 所有刺激目标的字符
        self.stim_target_text = StimulationConfig.STIM_TARGET_TEXT
        # 刺激规则（行列闪烁）
        self.stim_target_rule = StimulationConfig.STIM_TARGET_RULE

        # TODO 这个路径看怎么安排比较好
        self.save_path = path

    def run(self, raw_data, sub_name):
        self.sub_name = sub_name
        # 数据格式处理
        af_format_data = self.__data_formatting(raw_data)
        # self.plot_target_nontarget(af_format_data)
        # 把 af_format_data 的 data 和 evt 分别给到 x, y, 便于下面书写
        # x shape: (channels, time_series, stims)
        # y shape: (stims,1)
        x, y = af_format_data['data'], af_format_data['evt'][:, [2]]

        # 如何使用 BLDA 这个类
        self.method.train(x, y)  # 训练模型，模型的 W 是存储在类中的, 若不训练测试将报错
        # 用训练完的 BLDA 进行测试，y_prob (stims,1), 其为 BLDA 预测的概率值，未做归一化
        y_prob = self.method.test(x)

        # 在训练数据上以非叠加平均方式计算字符准确率
        char_acc = cal_char_acc(StimulationConfig, y_prob,
                                af_format_data['evt'][:, 1:3])
        print(
            f"character accuracy is {char_acc:.5f} (without round average).\n")

        # 在训练数据上以叠加平均方式计算字符准确率
        y_prob, evt_tar = round_average(
            StimulationConfig, y_prob, af_format_data['evt'][:, 1:3])
        char_acc = cal_char_acc(StimulationConfig, y_prob, evt_tar)
        print(f"character accuracy is {char_acc:.5f}.\n")

        # 一个交叉验证的例子
        results = self.__cv_result((x, y), k=self.cv_num, criterion='acc')

        # 保存最好的模型
        self.method.load(results['model_list']
                         [results['best_index']])  # 加载交叉验证中最好的模型

        self.method.save(self.save_path)  # 保存模型

    def __data_formatting(self, data, verbose=True):
        """
        数据预处理
        滤波 -> 重参考 -> 通道选择 -> 数据分割

        input
        data (dict): 原始数据字典
            data (channels， time_series): 原始信号
            evt (stim_num * rounds * trials, 2): event
            ch_nanm (list): 通道名称列表
        verbose: 是否打印一些信息

        output:
        af_format (channels * time_series): 预处理后的数据

        """
        global idx_non_re_samp

        af_format = dict(data=[], evt=[])
        raw_data = data['data']
        raw_evt = data['evt'][(data['evt'][:, 1] < 200),
                              :]  # 因为是训练，这句话里滤掉了很多标签
        # 滤波，包括带通滤波和陷波滤波
        tmp0_data = self.__bandpass_notch_filter(raw_data)

        # 重参考 T7 T8
        if len(self.re_samp) > 0:
            idx_re_samp, idx_non_re_samp = channel_name_to_index(
                data['ch_name'], self.re_samp)  # 记录数据通道中是否包含重参考通道
            tmp_data = tmp0_data - \
                np.tile(np.mean(tmp0_data[idx_re_samp, :],
                        axis=0), (tmp0_data.shape[0], 1))
        else:
            tmp_data = tmp0_data

        # 确定选择通道的索引，这里有点资源冗杂了，其实是可以精简一下的

        self.select_channel, _ = channel_name_to_index(
            data['ch_name'], self.select_channel_name)

        # 标签处理
        tmp_evt = np.concatenate((raw_evt, np.zeros(
            (raw_evt.shape[0], 1))), axis=1).astype(int)  # 在这里加一列0，用来标记是否是目标
        tar_evt = np.where(tmp_evt[:, 1] > 100)[0]

        # 数据分割，下采样
        for i_tar_index in range(len(tar_evt)):
            tar_idx = tmp_evt[tar_evt[i_tar_index]][1] - self.smallest_tar_evt
            # 这边是看一下目标字符是在刺激规则中的哪个位置
            tar_loc = find_element(self.stim_target_rule, tar_idx)

            if len(tar_loc) == 0:
                print('该字符不属于本范式，请检查代码')
            if i_tar_index == len(tar_evt) - 1:
                new_evt = tmp_evt[tar_evt[i_tar_index] + 1:, :]
            else:
                new_evt = tmp_evt[tar_evt[i_tar_index] +
                                  1:tar_evt[i_tar_index + 1], :]

            for i_tar_loc in tar_loc:
                new_evt[new_evt[:, 1] == i_tar_loc + 1, 2] = 1

            # 切割数据及下采样及通道选择
            for i_stim in range(new_evt.shape[0]):
                tmp1_data = tmp_data[self.select_channel,
                                     new_evt[i_stim, 0]:new_evt[i_stim, 0] + self.cal_len]
                # 下面的一行下采样其实可以考虑一下要不要用均值的方式去平滑
                # data_after_downsample = np.zeros((tmp1_data.shape[0], tmp1_data.shape[1]//self.down_sample_rate),
                #                                  dtype=tmp1_data.dtype)
                # for i_sample in range(self.down_sample_rate):
                #     data_after_downsample[:, :] += tmp1_data[:, i_sample::self.down_sample_rate]
                # data_after_downsample[:, :] = data_after_downsample[:, :] / self.down_sample_rate
                # af_format['data'].append(data_after_downsample)
                # 下面这个是单点采样形式
                af_format['data'].append(tmp1_data[:, ::self.down_sample_rate])
                af_format['evt'].append(new_evt[i_stim, :])

        af_format['data'] = np.stack(af_format['data'], axis=2)
        af_format['evt'] = np.stack(af_format['evt'], axis=0)

        if verbose:
            print(
                f"Data formatting is finished, there are totally {af_format['data'].shape[2]} stims.\n")
        return af_format

    def plot_target_nontarget(self, data):
        # TODO 这个函数的功能是？
        target_data = data['data'][:, :, data['evt'][:, 2] == 1]
        nontarget_data = data['data'][:, :, data['evt'][:, 2] == 0]
        target_data.mean(axis=(0, 2))
        # return data

    def __bandpass_notch_filter(self, data):
        """
        对输入数据进行滤波

        input
        data (channels * time_serise): 输入数据

        output
        af_filter_data (channels * time_series): 滤波后数据
        """
        fs = self.filter_param['sample_frequency']
        f1 = self.filter_param['notch_f']
        f_1 = self.filter_param['band_f_up']
        f_2 = self.filter_param['band_f_down']
        # 陷波滤波器
        Q = 35.0  # Quality factor
        b0, a0 = signal.iirnotch(f1, Q, fs)
        af_notch_data = signal.filtfilt(
            b0, a0, data, axis=1)  # 维度的默认值就是-1，其实用默认值也行
        # 带通滤波
        order = 2  # 阶数
        wn = [f_1 * 2 / fs, f_2 * 2 / fs]
        b1, a1 = signal.butter(order, wn, 'bandpass', analog=True)
        af_filter_data = signal.filtfilt(b1, a1, af_notch_data, axis=1)
        return af_filter_data

    def __cv_result(self, data, k=8, criterion='acc', verbose=True):
        """
        交叉验证

        inputs
        data (tuple(x, y)): 用于交叉验证的数据
            x  : (channels, time_series, stims)
            y  : (stims,1)
        k: 交叉验证折数
        criterion: 评估标准， 目前只支持 acc
        verbose: 是否打印一些信息

        output
        results: 结果字典
        """
        kf = KFold(n_splits=k)  # 定义 sklearn 的 KFold
        x, y = data[0], data[1]  # 提取x，y
        all_index = np.arange(y.shape[0])  # 所有样本的索引
        if criterion == 'acc':
            eval_func = cal_acc  # 设置用于评估的函数
        else:
            NotImplementedError  # 如果不是 acc, 抛出一个未实现错误

        model_list = []
        criteria = []
        best_index, best_criterion = -1, 0
        for i, (train_idx, test_idx) in enumerate(kf.split(all_index)):
            self.method.train(x[:, :, train_idx], y[train_idx, :])  # 训练
            y_prob = self.method.test(x[:, :, test_idx])  # 预测
            y_prob_n = post_process_y_prob(y_prob)  # 归一化
            criterion = eval_func(y_prob_n, y[test_idx, :])  # 计算评估指标
            # # TODO 考虑是否加入 train 的评估
            # y_prob_train = self.method.test(x[:, :, train_idx])
            # y_prob_train_n = post_process_y_prob(y_prob_train)
            # criterion_train = eval_func(y_prob_train_n, y[train_idx, :])
            # print(f"train criterion is {criterion_train}.")

            criteria.append(criterion)
            model_list.append(self.method.save())

            # 根据评估标准确定最好一折的索引
            if criterion > best_criterion:
                best_index = len(criteria) - 1
                best_criterion = criterion

            if verbose:
                print("The {} fold is finished and get criterion {:.5f}. --> Best criterion is {:.5f}\n"
                      .format(i+1, criterion, best_criterion))

        results = {
            'model_list': model_list,  # 交叉验证的各个模型 (list)
            'criteria': criteria,      # 各个模型对应的评估指标 (list)
            'best_index': best_index,  # 最好的一折的索引
        }

        return results
